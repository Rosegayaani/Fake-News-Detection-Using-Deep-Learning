{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frontend.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixFhrOAOD7HJ",
        "outputId": "8eeb24d7-f2b4-4377-e098-e3fb8b975fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1iGbuPoDX1ubowjWkm94swgP0j8tNcXO8/project\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DEjb21Zuswh",
        "outputId": "c7111e7f-28d1-428a-e42a-30e7a9507fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install colabcode -q\n",
        "! pip install fastapi -q\n",
        "! pip install python-multipart -q\n",
        "! ngrok authtoken 2ALhkxhyrZeVRrEoQiBMG94S9li_2AKoUmr4UTbzpKSPybaHm"
      ],
      "metadata": {
        "id": "IZdDcw19FaxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19eaa404-5234-4d94-c652-acf22909574d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 45 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 745 kB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 344 kB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 428 kB 57.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 561 kB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 56.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 58.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 55.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 57.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 46.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 59.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 59.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 61.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 58.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 129 kB 59.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 124 kB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 124 kB 58.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 122 kB 54.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 122 kB 61.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 122 kB 60.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 122 kB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 54.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 25.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 55.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for json5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI\n",
        "import logging\n",
        "from fastapi import FastAPI, Form, Request, Depends\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm\n",
        "import pickle\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from fastapi import FastAPI, Request\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.templating import Jinja2Templates"
      ],
      "metadata": {
        "id": "p3CZk143GLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc = ColabCode(port = 11000, code = False)"
      ],
      "metadata": {
        "id": "mN_PfBpAIWGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_models():\n",
        "    with open('model/tokenizer.json') as f:\n",
        "        tokenizer = tokenizer_from_json(f.read())\n",
        "\n",
        "    # Model reconstruction from JSON file\n",
        "    with open('model/model_architecture.json', 'r') as f:\n",
        "        model = model_from_json(f.read())\n",
        "\n",
        "    # Load weights into the new model\n",
        "    model.load_weights('model/model_weights.h5')\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "8xpKFtBoGqMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "app = FastAPI(title = \"Fake News Detecting Model\", description=\"Find the fake news with FastAPI and colab\")\n",
        "templates = Jinja2Templates(directory=\"templates/\")\n",
        "@app.get(\"/\")\n",
        "def index(request: Request):\n",
        "  return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
        "@app.post(\"/\")\n",
        "def get_prediction(request: Request, news: str = Form(...)):\n",
        "  user_input = news\n",
        "  data = []\n",
        "  maxlen = 700\n",
        "  data.append(news)\n",
        "  my_model, my_tokenizer = load_models()\n",
        "  x = my_tokenizer.texts_to_sequences(data)\n",
        "  x = pad_sequences(x, maxlen=maxlen)\n",
        "  pred = (my_model.predict(x) >= 0.5).astype(int)\n",
        "  result = pred\n",
        "  if pred[0][0] == 1:\n",
        "    result = \"True\"\n",
        "  elif pred[0][0] == 0:\n",
        "    result = \"False\"\n",
        "  else:\n",
        "    result = \"Please give a valid input\"\n",
        "  return templates.TemplateResponse('result.html', {\"request\": request,\"user_input\": news, \"result\": result})\n",
        "cc.run_app(app = app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjn-GtOJIFrG",
        "outputId": "d7c613f6-9306-46fa-eeef-fc39fb6dd600"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://c435-35-194-0-61.ngrok.io\" -> \"http://localhost:11000\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [60]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:11000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     2409:4072:6c99:809:5599:63fd:61ea:5941:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4072:6c99:809:5599:63fd:61ea:5941:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in callback BaseAsyncIOLoop._handle_events(14, 1)\n",
            "handle: <Handle BaseAsyncIOLoop._handle_events(14, 1)>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\", line 203, in run\n",
            "    self._context.run(update_from_context, ctx)\n",
            "RuntimeError: cannot enter context: <Context object at 0x7f0bab830d20> is already entered\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     2409:4072:6c99:809:5599:63fd:61ea:5941:0 - \"POST / HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in callback BaseAsyncIOLoop._handle_events(14, 1)\n",
            "handle: <Handle BaseAsyncIOLoop._handle_events(14, 1)>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\", line 203, in run\n",
            "    self._context.run(update_from_context, ctx)\n",
            "RuntimeError: cannot enter context: <Context object at 0x7f0bab830d20> is already entered\n",
            "Exception in callback BaseAsyncIOLoop._handle_events(14, 1)\n",
            "handle: <Handle BaseAsyncIOLoop._handle_events(14, 1)>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\", line 203, in run\n",
            "    self._context.run(update_from_context, ctx)\n",
            "RuntimeError: cannot enter context: <Context object at 0x7f0bab830d20> is already entered\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     2409:4072:6c99:809:5599:63fd:61ea:5941:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4072:6c99:809:5599:63fd:61ea:5941:0 - \"POST / HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    }
  ]
}